<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
</head>

<body>

    <input type="text" id="text-input" placeholder="Enter text to summarize or speak" />
    <button id="summarize_button">Test Summarize</button>
    <button id="text_to_speech_button">Test Text to Speech</button>

    <div id="whisper-block">
        <input type="file" id="whisper-file" accept="audio/*" />
        <button id="speech-to-text-button">Test Speech to Text</button>
    </div>

    <div id="ocr-block">
        <input type="file" id="ocr-file" accept="image/*" />
        <button id="image-to-text-button">Test Image to Text</button>
    </div>

    <div id="image-classify-block">
        <input type="file" id="image-classify-file" accept="image/*" />
        <button id="image-classify-button">Test Image Classification</button>
    </div>

    <div id="do-rag-block">
        <button id="do-rag-button">Test DoRAG Search</button>
    </div>


    <script type="module">
        document.querySelector("#summarize_button").addEventListener("click", async () => {
            console.log("summarizing")
            const { summarize } = await import("/dist/index.js");

            const text = document.querySelector("#text-input").value;
            const summary = await summarize(text);
            console.log(summary);
        });

        document.querySelector("#text_to_speech_button").addEventListener("click", async () => {
            const { textToSpeech } = await import("/dist/index.js");

            const text = document.querySelector("#text-input").value;
            const audioData = await textToSpeech(text);
            console.log(audioData);

            // audioData.data is a float32Array
            // play this audio
            const audioContext = new AudioContext();
            const audioBuffer = audioContext.createBuffer(1, audioData.audio.length, audioData.sampling_rate);
            audioBuffer.getChannelData(0).set(audioData.audio);
            const source = audioContext.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(audioContext.destination);
            source.start(0);
            console.log("Playing audio...");
        });

        document.querySelector("#speech-to-text-button").addEventListener("click", async () => {
            const { transcribeAudioFile } = await import("/dist/index.js");

            const file = document.querySelector("#whisper-file").files[0];
            const text = await transcribeAudioFile(file);
            console.log(text);
        });

        document.querySelector("#image-to-text-button").addEventListener("click", async () => {
            const { ocr } = await import("/dist/index.js");

            const file = document.querySelector("#ocr-file").files[0];
            const text = await ocr(URL.createObjectURL(file));
            console.log(text);
            URL.revokeObjectURL(file);
        });

        document.querySelector("#image-classify-button").addEventListener("click", async () => {
            const { classifyImage } = await import("/dist/index.js");

            const file = document.querySelector("#image-classify-file").files[0];
            const text = await classifyImage(URL.createObjectURL(file));
            console.log(text);
            URL.revokeObjectURL(file);
        });

        document.querySelector("#do-rag-button").addEventListener("click", async () => {
            const { doRAGSearch } = await import("/dist/index.js");

            // open up .txt files using the file system access api
            window.showOpenFilePicker().then(async (file) => {
                const fileBlob = await file[0].getFile();
                const text = await fileBlob.text();

                const query = "What is a coho?";
                const ragQuery = await doRAGSearch([text], query);
                console.log(ragQuery);
            });

        });
    </script>
</body>

</html>